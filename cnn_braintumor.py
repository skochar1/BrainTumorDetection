# -*- coding: utf-8 -*-
"""CNN_BrainTumor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tWNDuNAtr-DVmnRXaAhQK63Y9R2aH6jE

## Loading the Data

Important: set Runtime type to GPU!
"""

! pip install kaggle --upgrade

! mkdir ~/.kaggle/

"""Go to "account" after clicking your icon. Get a new API token. Upload it into this notebook."""

! cp kaggle.json ~/.kaggle/

"""Skip this step for now, come back to it after kaggle dataset download."""

! chmod 600 /root/.kaggle/kaggle.json

"""Go to the dataset, click the three dots on the right, and click "Copy API command". Add an exclamation mark and then paste it here.

"""

! kaggle datasets download -d sartajbhuvaji/brain-tumor-classification-mri

! mkdir dataset

"""Unzip the images, since the file that contains them is a zip file."""

! unzip brain-tumor-classification-mri.zip -d dataset

"""Play around with git commands like ls, pwd, etc."""

! ls dataset/

! ls dataset/Testing

! ls dataset/Testing/no_tumor

"""## Step 2: Start working with images
Start off by importing useful libraries.
"""

import matplotlib.pyplot as plt
import numpy as np 
import cv2 as cv
import os
import PIL

# how an image looks
I = np.asarray(PIL.Image.open("dataset/Testing/glioma_tumor/image(2).jpg"))
im = PIL.Image.fromarray(np.uint8(I))
im

I.shape # see the dimensions of the image here

# define parameters for Keras to load data into variables; compresses images
image_size = (150, 150)
img_height = 150
img_width = 150
batch_size = 32

"""Now, we will import the images into Keras. Keras will allow us to quickly differentiate between training and testing data."""

# create the datasets using Keras DataSet object
import tensorflow as tf 
from tensorflow import keras

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    "dataset/Training/",
    image_size=image_size,
    batch_size=batch_size,
)
test_ds = tf.keras.preprocessing.image_dataset_from_directory(
    "dataset/Testing/",
    image_size=image_size,
    batch_size=batch_size,
)

im_classes = {
  0 : 'Glioma',
  1 : 'Meningioma',
  2 : 'No Tumor',
  3 : 'Pituitary',
}
class_labels = list(im_classes.values())
num_classes = len(class_labels)

"""## Step 3: Exploratory Data Analysis

We will first look inside the **training dataset** and walk through it.
"""

# EDA - look at proportion of each class inside the training dataset
import os 

images_per_class_training = {}
for folder in os.listdir("dataset/Training"):
  images_per_class_training[folder] = len(os.listdir(f'dataset/Training/{folder}')) # get the size of each folder (ie how many images there are in each)

print(images_per_class_training)

"""We want each type of image to have roughly the same weightage in terms of number of them in the total dataset. Let's check the proportions."""

dataset_size = sum(images_per_class_training.values())

for key, index in images_per_class_training.items():
  images_per_class_training[key] = round(images_per_class_training[key] / dataset_size,3)

print(images_per_class_training)

"""Let's see a visualization of the proportions:"""

# Pie chart, where the slices will be ordered and plotted counter-clockwise:
labels = images_per_class_training.keys()
sizes = images_per_class_training.values()
explode = (0.05, 0.05, 0.05, 0.05) 

fig1, ax1 = plt.subplots()
ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',
        colors=['#e0a760','#1bde50','#32c5db','#3777bd'], 
        shadow=True, startangle=90)
ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

plt.show()

"""Hmm... these proportions don't look even. In the future, to enhance this model, we would want to add more no_tumor images.

We will now look inside the **testing dataset** and walk through it.
"""

# EDA - look at proportion of each class inside the testing dataset

images_per_class_testing = {}
for folder in os.listdir("dataset/Testing"):
  images_per_class_testing[folder] = len(os.listdir(f'dataset/Testing/{folder}'))

print(images_per_class_testing)

"""Let's see a visualization of the proportions:"""

# Pie chart, where the slices will be ordered and plotted counter-clockwise:
labels = images_per_class_testing.keys()
sizes = images_per_class_testing.values()
explode = (0.05, 0.05, 0.05, 0.05) 

fig1, ax1 = plt.subplots()
ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',
        colors=['#e0a760','#1bde50','#32c5db','#3777bd'], 
        shadow=True, startangle=90)
ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

plt.show()

# EDA - randomly sampling 9 images across all the categories
import matplotlib.pyplot as plt

plt.figure(figsize=(14, 8))
for images, labels in train_ds.take(1):
    
    for i in range(24):
        ax = plt.subplot(4, 6, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.title(im_classes[int(labels[i])])
        plt.axis("off")

"""## Step 4: Modeling

Kick off the machine learning and start training the model.
"""

from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten

num_classes = 4

model = Sequential([
  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(num_classes)
])

model.compile(optimizer='adam', # adam is best optimizer (highest accuracy)
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.summary()

"""Time to start training! Note: make sure Runtime type is set to GPU for increased speed."""

epochs=10

history = model.fit(
  train_ds,
  validation_data=test_ds,
  epochs=epochs,
  batch_size=batch_size
)

"""By the end, we have a ~99% training accuracy (images the model has seen) and a ~73% testing data accuracy (images the model has never seen these before). 

Now, we want to see which tumor types are reducing accuracy and why.
"""

from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
import pandas as pd
import seaborn as sns

def get_preds_and_trues(model_used, ds): # compares predicted values to true values
  trues = []
  preds = []
  for input, labels in ds:
    batch_predictions = model_used.predict(x=input)
    for pred in batch_predictions:
      preds.append(np.argmax(tf.nn.softmax(pred)))
    for label in labels:
      trues.append(int(label))
  return trues, preds # returns tuple with 2 lists in it

def get_confusion_df(model, val_ds):
  # column is what it actually is, row is prediction
  # labels running on top is predicted
  # labels running on side is actual

  trues, preds = get_preds_and_trues(model, val_ds)
  confusion = confusion_matrix(y_true = trues, y_pred = preds)
  confusion_df = pd.DataFrame(confusion, index = class_labels, columns = class_labels)
  
  return confusion_df # returns a dataframe for comparison purposes

def plot_heamtmap(confusion_matrix, name): 
  # figure
  fig, ax = plt.subplots(figsize=(11, 9))

  # plot heatmap
  sns.heatmap(confusion_matrix, annot = True, cmap="Blues", vmin= 0, vmax=120, 
              square=True, linewidth=0.8, fmt='g', 
              xticklabels=class_labels, yticklabels=class_labels,
              annot_kws={'fontsize':15})
  # xticks
  ax.xaxis.tick_top()

  # axis labels
  plt.xlabel('PREDICTED')
  plt.ylabel('ACTUAL')

  # title
  title = f'{name} Performance\n'.upper()
  plt.title(title, loc='left')
  plt.show()

"""Read heatmap:

*   We want diagonal to be dark
*   Vertical categories (y-axis) are what the images should be
*   Horizontal categories (x-axis) are how many of the specific tumor the model classified as other tumors

"""

cnn_df = get_confusion_df(model, test_ds)
plot_heamtmap(cnn_df, 'Convolutional NN')